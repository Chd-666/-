import streamlit as st
import requests
import json

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Ollama å¯¹è¯åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æ ‡é¢˜
st.title("Ollama Ã— Streamlit å¯¹è¯ç•Œé¢")
st.caption("ä¸æœ¬åœ°Ollamaæ¨¡å‹è¿›è¡Œäº¤äº’")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("é…ç½®")
    # OllamaæœåŠ¡åœ°å€ï¼ˆé»˜è®¤ç«¯å£11434ï¼‰
    ollama_base_url = st.text_input(
        "Ollama APIåœ°å€",
        value="http://localhost:11434",
        help="é»˜è®¤æœ¬åœ°åœ°å€ä¸º http://localhost:11434"
    )
    # é€‰æ‹©æ¨¡å‹ï¼ˆéœ€æå‰é€šè¿‡ollama pullä¸‹è½½ï¼‰
    model_name = st.text_input(
        "æ¨¡å‹åç§°",
        value="qwen3:0.6b",  # å¯æ›¿æ¢ä¸ºå…¶ä»–æ¨¡å‹å¦‚gemmaã€qwenç­‰
        help="éœ€å¡«å†™Ollamaä¸­å·²å­˜åœ¨çš„æ¨¡å‹åç§°"
    )
    # å¯¹è¯å‚æ•°
    temperature = st.slider("æ¸©åº¦ï¼ˆåˆ›é€ æ€§ï¼‰", 0.0, 1.0, 0.7, 0.1)
    max_tokens = st.slider("æœ€å¤§å›å¤é•¿åº¦", 100, 2000, 500, 100)

# åˆå§‹åŒ–å¯¹è¯å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²å¯¹è¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # è°ƒç”¨Ollama APIç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        url = f"{ollama_base_url}/api/chat"
        payload = {
            "model": model_name,
            "messages": st.session_state.messages,  # ä¼ å…¥å®Œæ•´å¯¹è¯å†å²
            "stream": True,  # æµå¼è¿”å›ï¼ˆé€å­—æ˜¾ç¤ºï¼‰
            "options": {
                "temperature": temperature,
                "max_tokens": max_tokens
            }
        }

        try:
            # å‘é€POSTè¯·æ±‚ï¼ˆæµå¼å“åº”ï¼‰
            with requests.post(url, json=payload, stream=True) as r:
                r.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
                for line in r.iter_lines():
                    if line:
                        # è§£ææµå¼è¿”å›çš„JSON
                        data = json.loads(line.decode("utf-8"))
                        # æå–å½“å‰ç‰‡æ®µå†…å®¹ï¼ˆå¤„ç†ç»“æŸæ ‡è®°ï¼‰
                        if "message" in data and "content" in data["message"]:
                            chunk = data["message"]["content"]
                            full_response += chunk
                            # å®æ—¶æ›´æ–°æ˜¾ç¤º
                            message_placeholder.markdown(full_response + "â–Œ")
                # ç§»é™¤å…‰æ ‡
                message_placeholder.markdown(full_response)
                
                # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response
                })

        except requests.exceptions.ConnectionError:
            st.error("æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·æ£€æŸ¥ï¼š\n1. Ollamaæ˜¯å¦å·²å¯åŠ¨\n2. APIåœ°å€æ˜¯å¦æ­£ç¡®ï¼ˆé»˜è®¤ç«¯å£11434ï¼‰")
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

# conda activate NLPAPI
# python -m streamlit run D:\Codes\NLPAPI\API.py
